{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4b3da0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import re, string\n",
    "from string import digits\n",
    "import contractions\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b76b4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pd.read_csv('data/B09GFLFMPS.csv')\n",
    "d2 = pd.read_csv('data/B09GFLXVH9.csv')\n",
    "\n",
    "data_raw = pd.concat([d1,d2],axis=0,ignore_index=True)\n",
    "data = data_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e8373d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3aa87d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "lng_model = fasttext.load_model('data/lid.176.ftz')\n",
    "def langdet(st):\n",
    "    if len(st)>1:\n",
    "        return detect(st)\n",
    "def fstlangdet(st):\n",
    "    if len(st)>1:\n",
    "        return lng_model.predict(st)[0][0].split('__')[2]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "976e175a",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\"\n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                           \"]+\", flags = re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dafe801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def titleBody(title,body,emoji_pattern):\n",
    "    title =str(title).lower()\n",
    "    body =str(body).lower()\n",
    "    if (title !=body)|(title not in body):\n",
    "        x = emoji_pattern.sub(r'', (title+' '+body).strip())\n",
    "        return contractions.fix(x).replace('nan','')\n",
    "    else:\n",
    "        x = emoji_pattern.sub(r'', body.strip())\n",
    "        return contractions.fix(x).replace('nan','')\n",
    "def clean(text):\n",
    "# Removes all special characters and numericals leaving the alphabets\n",
    "    text = re.sub('[^A-Za-z]+', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa52693d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = data.apply(lambda x: titleBody(x['review_title'],x['review_body'],emoji_pattern),axis=1)\n",
    "data['review'] = data['review'].apply(lambda x: re.compile('[%s]' % re.escape(string.punctuation)).sub(' ',(x)))\n",
    "data['review'] = data['review'].apply(lambda x: x.translate(str.maketrans('', '', digits)))\n",
    "data['review'] = data['review'].apply(lambda x: re.sub(\"\\s\\s+\" , \" \", x))\n",
    "data['review'] = data['review'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23645c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['fstlanguage'] = data['review'].apply(lambda x: fstlangdet(x))\n",
    "#data_review = data[data['fstlanguage']=='en'][['review']]\n",
    "data['fstlanguage'].value_counts()\n",
    "data   = data[data['fstlanguage']=='en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a0bed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4aed5a23",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "259a1a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('sentiwordnet')\n",
    "from nltk.corpus import sentiwordnet as swn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c160c12",
   "metadata": {},
   "source": [
    "for sentiment analysis, i am not removing the stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "687b03ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_stop_pos(text):\n",
    "    tags = pos_tag(word_tokenize(text))\n",
    "    newlist = []\n",
    "    for word, tag in tags:\n",
    "        newlist.append(tuple([word, pos_dict.get(tag[0])]))\n",
    "    return newlist\n",
    "\n",
    "def lemmatize(pos_data):\n",
    "    lemma_rew = \" \"\n",
    "    for word, pos in pos_data:\n",
    "        if not pos:\n",
    "            lemma = word\n",
    "            lemma_rew = lemma_rew + \" \" + lemma\n",
    "        else:\n",
    "            lemma = wordnet_lemmatizer.lemmatize(word, pos=pos)\n",
    "            lemma_rew = lemma_rew + \" \" + lemma\n",
    "    return lemma_rew\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1dfa8206",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dict = {'J':wordnet.ADJ, 'V':wordnet.VERB, 'N':wordnet.NOUN, 'R':wordnet.ADV}\n",
    "\n",
    "data_review = data[['review']]\n",
    "data_review['review_clean'] = data_review['review'].apply(clean)\n",
    "data_review['POS tagged'] = data_review['review_clean'].apply(token_stop_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "230739f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "data_review['Lemma'] = data_review['POS tagged'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5ea9850c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>POS tagged</th>\n",
       "      <th>Lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>value for money if you are looking for a budge...</td>\n",
       "      <td>value for money if you are looking for a budge...</td>\n",
       "      <td>[(value, n), (for, None), (money, n), (if, Non...</td>\n",
       "      <td>value for money if you be look for a budget ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>works a like a charm in this price range i get...</td>\n",
       "      <td>works a like a charm in this price range i get...</td>\n",
       "      <td>[(works, v), (a, None), (like, None), (a, None...</td>\n",
       "      <td>work a like a charm in this price range i ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>value for money i bought this for my mother wh...</td>\n",
       "      <td>value for money i bought this for my mother wh...</td>\n",
       "      <td>[(value, n), (for, None), (money, n), (i, n), ...</td>\n",
       "      <td>value for money i buy this for my mother who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good budget mobile good enough mobile in this ...</td>\n",
       "      <td>good budget mobile good enough mobile in this ...</td>\n",
       "      <td>[(good, a), (budget, n), (mobile, n), (good, a...</td>\n",
       "      <td>good budget mobile good enough mobile in thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>camera only camera quality not good</td>\n",
       "      <td>camera only camera quality not good</td>\n",
       "      <td>[(camera, n), (only, r), (camera, n), (quality...</td>\n",
       "      <td>camera only camera quality not good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19946</th>\n",
       "      <td>good phone superb quality mobile phone and cam...</td>\n",
       "      <td>good phone superb quality mobile phone and cam...</td>\n",
       "      <td>[(good, a), (phone, n), (superb, n), (quality,...</td>\n",
       "      <td>good phone superb quality mobile phone and c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19947</th>\n",
       "      <td>exslent mobile sarvis is good</td>\n",
       "      <td>exslent mobile sarvis is good</td>\n",
       "      <td>[(exslent, n), (mobile, n), (sarvis, n), (is, ...</td>\n",
       "      <td>exslent mobile sarvis be good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19948</th>\n",
       "      <td>best product in this price range good battery ...</td>\n",
       "      <td>best product in this price range good battery ...</td>\n",
       "      <td>[(best, a), (product, n), (in, None), (this, N...</td>\n",
       "      <td>best product in this price range good batter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19949</th>\n",
       "      <td>very fast delivery awesome</td>\n",
       "      <td>very fast delivery awesome</td>\n",
       "      <td>[(very, r), (fast, r), (delivery, n), (awesome...</td>\n",
       "      <td>very fast delivery awesome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19950</th>\n",
       "      <td>best</td>\n",
       "      <td>best</td>\n",
       "      <td>[(best, a)]</td>\n",
       "      <td>best</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19160 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  \\\n",
       "0      value for money if you are looking for a budge...   \n",
       "1      works a like a charm in this price range i get...   \n",
       "2      value for money i bought this for my mother wh...   \n",
       "3      good budget mobile good enough mobile in this ...   \n",
       "4                    camera only camera quality not good   \n",
       "...                                                  ...   \n",
       "19946  good phone superb quality mobile phone and cam...   \n",
       "19947                      exslent mobile sarvis is good   \n",
       "19948  best product in this price range good battery ...   \n",
       "19949                         very fast delivery awesome   \n",
       "19950                                               best   \n",
       "\n",
       "                                            review_clean  \\\n",
       "0      value for money if you are looking for a budge...   \n",
       "1      works a like a charm in this price range i get...   \n",
       "2      value for money i bought this for my mother wh...   \n",
       "3      good budget mobile good enough mobile in this ...   \n",
       "4                    camera only camera quality not good   \n",
       "...                                                  ...   \n",
       "19946  good phone superb quality mobile phone and cam...   \n",
       "19947                      exslent mobile sarvis is good   \n",
       "19948  best product in this price range good battery ...   \n",
       "19949                         very fast delivery awesome   \n",
       "19950                                               best   \n",
       "\n",
       "                                              POS tagged  \\\n",
       "0      [(value, n), (for, None), (money, n), (if, Non...   \n",
       "1      [(works, v), (a, None), (like, None), (a, None...   \n",
       "2      [(value, n), (for, None), (money, n), (i, n), ...   \n",
       "3      [(good, a), (budget, n), (mobile, n), (good, a...   \n",
       "4      [(camera, n), (only, r), (camera, n), (quality...   \n",
       "...                                                  ...   \n",
       "19946  [(good, a), (phone, n), (superb, n), (quality,...   \n",
       "19947  [(exslent, n), (mobile, n), (sarvis, n), (is, ...   \n",
       "19948  [(best, a), (product, n), (in, None), (this, N...   \n",
       "19949  [(very, r), (fast, r), (delivery, n), (awesome...   \n",
       "19950                                        [(best, a)]   \n",
       "\n",
       "                                                   Lemma  \n",
       "0        value for money if you be look for a budget ...  \n",
       "1        work a like a charm in this price range i ge...  \n",
       "2        value for money i buy this for my mother who...  \n",
       "3        good budget mobile good enough mobile in thi...  \n",
       "4                    camera only camera quality not good  \n",
       "...                                                  ...  \n",
       "19946    good phone superb quality mobile phone and c...  \n",
       "19947                      exslent mobile sarvis be good  \n",
       "19948    best product in this price range good batter...  \n",
       "19949                         very fast delivery awesome  \n",
       "19950                                               best  \n",
       "\n",
       "[19160 rows x 4 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c77b3b6",
   "metadata": {},
   "source": [
    "### Sentiment Analysis using TextBlob:\n",
    "TextBlob is a Python library for processing textual data. It provides a consistent API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, and more.\n",
    "\n",
    "The two measures that are used to analyze the sentiment are:\n",
    "\n",
    "    Polarity – talks about how positive or negative the opinion is\n",
    "    Subjectivity – talks about how subjective the opinion is, Subjective sentences generally refer to personal opinion, emotion, or judgment. \n",
    "    \n",
    "TextBlob(text).sentiment gives us the Polarity, Subjectivity values.\n",
    "\n",
    "    Polarity ranges from -1 to 1 (1 is more positive, 0 is neutral, -1 is more negative)\n",
    "    Subjectivity ranges from 0 to 1(0 being very objective and 1 being very subjective)\n",
    "    \n",
    "    \n",
    "Textblob will ignore the words that it doesn’t know, it will consider words and phrases that it can assign polarity to and averages to get the final score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "48146a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate subjectivity\n",
    "def getSubjectivity(review):\n",
    "    return TextBlob(review).sentiment.subjectivity\n",
    "    # function to calculate polarity\n",
    "def getPolarity(review):\n",
    "    return TextBlob(review).sentiment.polarity\n",
    "\n",
    "# function to analyze the reviews\n",
    "def mapScore(score):\n",
    "    if score < 0:\n",
    "        return 'Negative'\n",
    "    elif score == 0:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a719e53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_review['Subjectivity'] = data_review['Lemma'].apply(getSubjectivity) \n",
    "data_review['Polarity'] = data_review['Lemma'].apply(getPolarity) \n",
    "data_review['TextBlobAnalysis'] = data_review['Polarity'].apply(mapScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f65a8783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    15236\n",
       "Negative     2511\n",
       "Neutral      1413\n",
       "Name: TextBlobAnalysis, dtype: int64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_review['TextBlobAnalysis'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d090c001",
   "metadata": {},
   "source": [
    "### Sentiment Analysis using VADER\n",
    "VADER stands for Valence Aware Dictionary and Sentiment Reasoner. Vader sentiment not only tells if the statement is positive or negative along with the intensity of emotion.\n",
    "\n",
    "It uses a list of lexical features (e.g. word) which are labeled as positive or negative according to their semantic orientation to calculate the text sentiment.   \n",
    "\n",
    "Vader sentiment returns the probability of a given input sentence to be \n",
    "\n",
    "Positive, negative, and neutral. \n",
    "\n",
    "Vader is optimized for social media data and can yield good results when used with data from twitter, facebook, etc.\n",
    "\n",
    "The main drawback with the rule-based approach for sentiment analysis is that the method only cares about individual words and completely ignores the context in which it is used. \n",
    "\n",
    "For example, “the party was savage” will be negative when considered by any token-based algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "57b02fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate vader sentiment\n",
    "def vadersentimentanalysis(review):\n",
    "    vs = analyzer.polarity_scores(review)\n",
    "    return vs['compound']\n",
    "    \n",
    "# function to analyse\n",
    "def vader_analysis(compound):\n",
    "    if compound >= 0.5:\n",
    "        return 'Positive'\n",
    "    elif compound <= -0.5 :\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b39c4e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    9898\n",
       "Neutral     7562\n",
       "Negative    1700\n",
       "Name: Vader Analysis, dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "data_review['Vader Sentiment'] = data_review['Lemma'].apply(vadersentimentanalysis)\n",
    "data_review['Vader Analysis'] = data_review['Vader Sentiment'].apply(vader_analysis)\n",
    "data_review['Vader Analysis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7cce12e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>POS tagged</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>TextBlobAnalysis</th>\n",
       "      <th>Vader Sentiment</th>\n",
       "      <th>Vader Analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>value for money if you are looking for a budge...</td>\n",
       "      <td>value for money if you are looking for a budge...</td>\n",
       "      <td>[(value, n), (for, None), (money, n), (if, Non...</td>\n",
       "      <td>value for money if you be look for a budget ...</td>\n",
       "      <td>0.640476</td>\n",
       "      <td>-0.162202</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.5182</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>works a like a charm in this price range i get...</td>\n",
       "      <td>works a like a charm in this price range i get...</td>\n",
       "      <td>[(works, v), (a, None), (like, None), (a, None...</td>\n",
       "      <td>work a like a charm in this price range i ge...</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.7964</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>value for money i bought this for my mother wh...</td>\n",
       "      <td>value for money i bought this for my mother wh...</td>\n",
       "      <td>[(value, n), (for, None), (money, n), (i, n), ...</td>\n",
       "      <td>value for money i buy this for my mother who...</td>\n",
       "      <td>0.494569</td>\n",
       "      <td>0.294864</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.7343</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good budget mobile good enough mobile in this ...</td>\n",
       "      <td>good budget mobile good enough mobile in this ...</td>\n",
       "      <td>[(good, a), (budget, n), (mobile, n), (good, a...</td>\n",
       "      <td>good budget mobile good enough mobile in thi...</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.7003</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>camera only camera quality not good</td>\n",
       "      <td>camera only camera quality not good</td>\n",
       "      <td>[(camera, n), (only, r), (camera, n), (quality...</td>\n",
       "      <td>camera only camera quality not good</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>-0.175000</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.3412</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19946</th>\n",
       "      <td>good phone superb quality mobile phone and cam...</td>\n",
       "      <td>good phone superb quality mobile phone and cam...</td>\n",
       "      <td>[(good, a), (phone, n), (superb, n), (quality,...</td>\n",
       "      <td>good phone superb quality mobile phone and c...</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.9042</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19947</th>\n",
       "      <td>exslent mobile sarvis is good</td>\n",
       "      <td>exslent mobile sarvis is good</td>\n",
       "      <td>[(exslent, n), (mobile, n), (sarvis, n), (is, ...</td>\n",
       "      <td>exslent mobile sarvis be good</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19948</th>\n",
       "      <td>best product in this price range good battery ...</td>\n",
       "      <td>best product in this price range good battery ...</td>\n",
       "      <td>[(best, a), (product, n), (in, None), (this, N...</td>\n",
       "      <td>best product in this price range good batter...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>-0.1262</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19949</th>\n",
       "      <td>very fast delivery awesome</td>\n",
       "      <td>very fast delivery awesome</td>\n",
       "      <td>[(very, r), (fast, r), (delivery, n), (awesome...</td>\n",
       "      <td>very fast delivery awesome</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.6557</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19950</th>\n",
       "      <td>best</td>\n",
       "      <td>best</td>\n",
       "      <td>[(best, a)]</td>\n",
       "      <td>best</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19160 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  \\\n",
       "0      value for money if you are looking for a budge...   \n",
       "1      works a like a charm in this price range i get...   \n",
       "2      value for money i bought this for my mother wh...   \n",
       "3      good budget mobile good enough mobile in this ...   \n",
       "4                    camera only camera quality not good   \n",
       "...                                                  ...   \n",
       "19946  good phone superb quality mobile phone and cam...   \n",
       "19947                      exslent mobile sarvis is good   \n",
       "19948  best product in this price range good battery ...   \n",
       "19949                         very fast delivery awesome   \n",
       "19950                                               best   \n",
       "\n",
       "                                            review_clean  \\\n",
       "0      value for money if you are looking for a budge...   \n",
       "1      works a like a charm in this price range i get...   \n",
       "2      value for money i bought this for my mother wh...   \n",
       "3      good budget mobile good enough mobile in this ...   \n",
       "4                    camera only camera quality not good   \n",
       "...                                                  ...   \n",
       "19946  good phone superb quality mobile phone and cam...   \n",
       "19947                      exslent mobile sarvis is good   \n",
       "19948  best product in this price range good battery ...   \n",
       "19949                         very fast delivery awesome   \n",
       "19950                                               best   \n",
       "\n",
       "                                              POS tagged  \\\n",
       "0      [(value, n), (for, None), (money, n), (if, Non...   \n",
       "1      [(works, v), (a, None), (like, None), (a, None...   \n",
       "2      [(value, n), (for, None), (money, n), (i, n), ...   \n",
       "3      [(good, a), (budget, n), (mobile, n), (good, a...   \n",
       "4      [(camera, n), (only, r), (camera, n), (quality...   \n",
       "...                                                  ...   \n",
       "19946  [(good, a), (phone, n), (superb, n), (quality,...   \n",
       "19947  [(exslent, n), (mobile, n), (sarvis, n), (is, ...   \n",
       "19948  [(best, a), (product, n), (in, None), (this, N...   \n",
       "19949  [(very, r), (fast, r), (delivery, n), (awesome...   \n",
       "19950                                        [(best, a)]   \n",
       "\n",
       "                                                   Lemma  Subjectivity  \\\n",
       "0        value for money if you be look for a budget ...      0.640476   \n",
       "1        work a like a charm in this price range i ge...      0.366667   \n",
       "2        value for money i buy this for my mother who...      0.494569   \n",
       "3        good budget mobile good enough mobile in thi...      0.566667   \n",
       "4                    camera only camera quality not good      0.800000   \n",
       "...                                                  ...           ...   \n",
       "19946    good phone superb quality mobile phone and c...      0.633333   \n",
       "19947                      exslent mobile sarvis be good      0.600000   \n",
       "19948    best product in this price range good batter...      0.500000   \n",
       "19949                         very fast delivery awesome      0.890000   \n",
       "19950                                               best      0.300000   \n",
       "\n",
       "       Polarity TextBlobAnalysis  Vader Sentiment Vader Analysis  \n",
       "0     -0.162202         Negative           0.5182       Positive  \n",
       "1      0.183333         Positive           0.7964       Positive  \n",
       "2      0.294864         Positive           0.7343       Positive  \n",
       "3      0.466667         Positive           0.7003       Positive  \n",
       "4     -0.175000         Negative          -0.3412        Neutral  \n",
       "...         ...              ...              ...            ...  \n",
       "19946  0.900000         Positive           0.9042       Positive  \n",
       "19947  0.700000         Positive           0.4404        Neutral  \n",
       "19948  0.800000         Positive          -0.1262        Neutral  \n",
       "19949  0.630000         Positive           0.6557       Positive  \n",
       "19950  1.000000         Positive           0.6369       Positive  \n",
       "\n",
       "[19160 rows x 9 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0849e7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiwordnetanalysis(pos_data):\n",
    "    sentiment = 0\n",
    "    tokens_count = 0\n",
    "    for word, pos in pos_data:\n",
    "        if not pos:\n",
    "            continue\n",
    "        lemma = wordnet_lemmatizer.lemmatize(word, pos=pos)\n",
    "        if not lemma:\n",
    "            continue\n",
    "        \n",
    "        synsets = wordnet.synsets(lemma, pos=pos)\n",
    "        if not synsets:\n",
    "            continue\n",
    "\n",
    "        # Take the first sense, the most common\n",
    "        synset = synsets[0]\n",
    "        swn_synset = swn.senti_synset(synset.name())\n",
    "        sentiment += swn_synset.pos_score() - swn_synset.neg_score()\n",
    "        tokens_count += 1\n",
    "        # print(swn_synset.pos_score(),swn_synset.neg_score(),swn_synset.obj_score())\n",
    "    if not tokens_count:\n",
    "        return 0\n",
    "    if sentiment>0:\n",
    "        return \"Positive\"\n",
    "    if sentiment==0:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "33007f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    14426\n",
       "Negative     3134\n",
       "Neutral      1438\n",
       "0             162\n",
       "Name: SWN analysis, dtype: int64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_review['SWN analysis'] = data_review['POS tagged'].apply(sentiwordnetanalysis)\n",
    "data_review['SWN analysis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "91af4d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>POS tagged</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>TextBlobAnalysis</th>\n",
       "      <th>Vader Sentiment</th>\n",
       "      <th>Vader Analysis</th>\n",
       "      <th>SWN analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>taimpass</td>\n",
       "      <td>taimpass</td>\n",
       "      <td>[(taimpass, n)]</td>\n",
       "      <td>taimpass</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>everything like</td>\n",
       "      <td>everything like</td>\n",
       "      <td>[(everything, n), (like, None)]</td>\n",
       "      <td>everything like</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>excellent</td>\n",
       "      <td>excellent</td>\n",
       "      <td>[(excellent, n)]</td>\n",
       "      <td>excellent</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>exloent supar</td>\n",
       "      <td>exloent supar</td>\n",
       "      <td>[(exloent, n), (supar, n)]</td>\n",
       "      <td>exloent supar</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>sparsh</td>\n",
       "      <td>sparsh</td>\n",
       "      <td>[(sparsh, n)]</td>\n",
       "      <td>sparsh</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19202</th>\n",
       "      <td>excellent</td>\n",
       "      <td>excellent</td>\n",
       "      <td>[(excellent, n)]</td>\n",
       "      <td>excellent</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19204</th>\n",
       "      <td>awesome</td>\n",
       "      <td>awesome</td>\n",
       "      <td>[(awesome, n)]</td>\n",
       "      <td>awesome</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19357</th>\n",
       "      <td>excellent</td>\n",
       "      <td>excellent</td>\n",
       "      <td>[(excellent, n)]</td>\n",
       "      <td>excellent</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19615</th>\n",
       "      <td>exellent</td>\n",
       "      <td>exellent</td>\n",
       "      <td>[(exellent, n)]</td>\n",
       "      <td>exellent</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19813</th>\n",
       "      <td>lol wonderful</td>\n",
       "      <td>lol wonderful</td>\n",
       "      <td>[(lol, n), (wonderful, n)]</td>\n",
       "      <td>lol wonderful</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.7579</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                review     review_clean                       POS tagged  \\\n",
       "101           taimpass         taimpass                  [(taimpass, n)]   \n",
       "279    everything like  everything like  [(everything, n), (like, None)]   \n",
       "371          excellent        excellent                 [(excellent, n)]   \n",
       "409      exloent supar    exloent supar       [(exloent, n), (supar, n)]   \n",
       "419             sparsh           sparsh                    [(sparsh, n)]   \n",
       "...                ...              ...                              ...   \n",
       "19202        excellent        excellent                 [(excellent, n)]   \n",
       "19204          awesome          awesome                   [(awesome, n)]   \n",
       "19357        excellent        excellent                 [(excellent, n)]   \n",
       "19615         exellent         exellent                  [(exellent, n)]   \n",
       "19813    lol wonderful    lol wonderful       [(lol, n), (wonderful, n)]   \n",
       "\n",
       "                   Lemma  Subjectivity  Polarity TextBlobAnalysis  \\\n",
       "101             taimpass          0.00       0.0          Neutral   \n",
       "279      everything like          0.00       0.0          Neutral   \n",
       "371            excellent          1.00       1.0         Positive   \n",
       "409        exloent supar          0.00       0.0          Neutral   \n",
       "419               sparsh          0.00       0.0          Neutral   \n",
       "...                  ...           ...       ...              ...   \n",
       "19202          excellent          1.00       1.0         Positive   \n",
       "19204            awesome          1.00       1.0         Positive   \n",
       "19357          excellent          1.00       1.0         Positive   \n",
       "19615           exellent          0.00       0.0          Neutral   \n",
       "19813      lol wonderful          0.85       0.9         Positive   \n",
       "\n",
       "       Vader Sentiment Vader Analysis SWN analysis  \n",
       "101             0.0000        Neutral            0  \n",
       "279             0.3612        Neutral            0  \n",
       "371             0.5719       Positive            0  \n",
       "409             0.0000        Neutral            0  \n",
       "419             0.0000        Neutral            0  \n",
       "...                ...            ...          ...  \n",
       "19202           0.5719       Positive            0  \n",
       "19204           0.6249       Positive            0  \n",
       "19357           0.5719       Positive            0  \n",
       "19615           0.0000        Neutral            0  \n",
       "19813           0.7579       Positive            0  \n",
       "\n",
       "[162 rows x 10 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_review[data_review['SWN analysis']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db79a570",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc6a68af",
   "metadata": {},
   "source": [
    "### Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d765b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as  pd\n",
    "from pprint import pprint# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel# spaCy for preprocessing\n",
    "import spacy# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "pyLDAvis.enable_notebook()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "813f7b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "#stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c24c7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tm = data[['review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f6926ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_tm.review.values.tolist()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffee96d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['value for money if you are looking for a budget phone within k go for this one this one delivers the promises they make and stands upto the expectation only the battery performance is little disappointing mah with no fast charging option but that does not make this one a showstopper unless you expect a beast out of below k budget smartphone with gb gb config with octa core non snapdragon processor this phone is the smart est choice for you at least at this moment in the market']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "970d1fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['value', 'for', 'money', 'if', 'you', 'are', 'looking', 'for', 'budget', 'phone', 'within', 'go', 'for', 'this', 'one', 'this', 'one', 'delivers', 'the', 'promises', 'they', 'make', 'and', 'stands', 'upto', 'the', 'expectation', 'only', 'the', 'battery', 'performance', 'is', 'little', 'disappointing', 'mah', 'with', 'no', 'fast', 'charging', 'option', 'but', 'that', 'does', 'not', 'make', 'this', 'one', 'showstopper', 'unless', 'you', 'expect', 'beast', 'out', 'of', 'below', 'budget', 'smartphone', 'with', 'gb', 'gb', 'config', 'with', 'octa', 'core', 'non', 'snapdragon', 'processor', 'this', 'phone', 'is', 'the', 'smart', 'est', 'choice', 'for', 'you', 'at', 'least', 'at', 'this', 'moment', 'in', 'the', 'market']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))            #deacc=True removes punctuations\n",
    "data_words = list(sent_to_words(data))\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36e2dbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['value', 'money', 'looking', 'budget', 'phone', 'within', 'go', 'one', 'one', 'delivers', 'promises', 'make', 'stands', 'upto', 'expectation', 'battery', 'performance', 'little', 'disappointing', 'mah', 'fast', 'charging', 'option', 'make', 'one', 'showstopper', 'unless', 'expect', 'beast', 'budget', 'smartphone', 'gb', 'gb', 'config', 'octa', 'core', 'non', 'snapdragon', 'processor', 'phone', 'smart', 'est', 'choice', 'least', 'moment', 'market']]\n"
     ]
    }
   ],
   "source": [
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) \n",
    "             if word not in stop_words] for doc in texts]\n",
    "\n",
    "data_words = remove_stopwords(data_words)\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86e9a5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['value', 'money', 'looking', 'budget', 'phone', 'within', 'go', 'one', 'one', 'delivers', 'promises', 'make', 'stands', 'upto', 'expectation', 'battery', 'performance', 'little', 'disappointing', 'mah', 'fast', 'charging', 'option', 'make', 'one', 'showstopper', 'unless', 'expect', 'beast', 'budget', 'smartphone', 'gb', 'gb', 'config', 'octa_core', 'non', 'snapdragon', 'processor', 'phone', 'smart', 'est', 'choice', 'least', 'moment', 'market']\n"
     ]
    }
   ],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ff4dd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for stopwords, bigrams, trigrams and lemmatization\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e37882c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['value', 'money', 'look', 'budget', 'phone', 'go', 'deliver', 'promise', 'make', 'stand', 'upto', 'expectation', 'battery', 'performance', 'little', 'disappointing', 'fast', 'charge', 'option', 'make', 'showstopper', 'expect', 'beast', 'budget', 'config', 'non', 'snapdragon', 'processor', 'phone', 'smart', 'e', 'choice', 'least', 'moment', 'market']]\n"
     ]
    }
   ],
   "source": [
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "037ff29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 2), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 2), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 2), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary \n",
    "id2word = corpora.Dictionary(data_lemmatized)  \n",
    "# Create Corpus \n",
    "texts = data_lemmatized  \n",
    "# Term Document Frequency \n",
    "corpus = [id2word.doc2bow(text) for text in texts]  \n",
    "# View \n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48208486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('battery', 1),\n",
       "  ('beast', 1),\n",
       "  ('budget', 2),\n",
       "  ('charge', 1),\n",
       "  ('choice', 1),\n",
       "  ('config', 1),\n",
       "  ('deliver', 1),\n",
       "  ('disappointing', 1),\n",
       "  ('e', 1),\n",
       "  ('expect', 1),\n",
       "  ('expectation', 1),\n",
       "  ('fast', 1),\n",
       "  ('go', 1),\n",
       "  ('least', 1),\n",
       "  ('little', 1),\n",
       "  ('look', 1),\n",
       "  ('make', 2),\n",
       "  ('market', 1),\n",
       "  ('moment', 1),\n",
       "  ('money', 1),\n",
       "  ('non', 1),\n",
       "  ('option', 1),\n",
       "  ('performance', 1),\n",
       "  ('phone', 2),\n",
       "  ('processor', 1),\n",
       "  ('promise', 1),\n",
       "  ('showstopper', 1),\n",
       "  ('smart', 1),\n",
       "  ('snapdragon', 1),\n",
       "  ('stand', 1),\n",
       "  ('upto', 1),\n",
       "  ('value', 1)]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7fa0a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f0d9cc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.125*\"reader\" + 0.120*\"finger_print\" + 0.114*\"back\" + 0.112*\"receive\" + '\n",
      "  '0.094*\"cover\" + 0.080*\"build\" + 0.045*\"rs\" + 0.023*\"offer\" + '\n",
      "  '0.014*\"goodcamera\" + 0.014*\"bright\"'),\n",
      " (1,\n",
      "  '0.607*\"mobile\" + 0.174*\"awesome\" + 0.128*\"worth\" + 0.007*\"gift\" + '\n",
      "  '0.004*\"father\" + 0.000*\"amazon\" + 0.000*\"superb\" + 0.000*\"day\" + '\n",
      "  '0.000*\"display\" + 0.000*\"amazing\"'),\n",
      " (2,\n",
      "  '0.333*\"buy\" + 0.141*\"slow\" + 0.117*\"thank\" + 0.069*\"normal\" + 0.059*\"app\" + '\n",
      "  '0.052*\"user\" + 0.029*\"start\" + 0.024*\"recommend\" + 0.015*\"sometimes\" + '\n",
      "  '0.013*\"youtube\"'),\n",
      " (3,\n",
      "  '0.472*\"fingerprint\" + 0.107*\"available\" + 0.000*\"sensor\" + 0.000*\"amazon\" + '\n",
      "  '0.000*\"cool\" + 0.000*\"simply\" + 0.000*\"amazing\" + 0.000*\"future\" + '\n",
      "  '0.000*\"lock\" + 0.000*\"day\"'),\n",
      " (4,\n",
      "  '0.335*\"quality\" + 0.323*\"camera\" + 0.173*\"bad\" + 0.056*\"look\" + '\n",
      "  '0.052*\"backup\" + 0.014*\"hai\" + 0.000*\"amazon\" + 0.000*\"display\" + '\n",
      "  '0.000*\"superb\" + 0.000*\"day\"'),\n",
      " (5,\n",
      "  '0.196*\"poor\" + 0.154*\"much\" + 0.104*\"smartphone\" + 0.053*\"perfect\" + '\n",
      "  '0.049*\"customer\" + 0.045*\"item\" + 0.039*\"thing\" + 0.036*\"give\" + '\n",
      "  '0.024*\"daily\" + 0.022*\"light\"'),\n",
      " (6,\n",
      "  '0.408*\"money\" + 0.303*\"value\" + 0.151*\"excellent\" + 0.021*\"accord\" + '\n",
      "  '0.019*\"function\" + 0.010*\"design\" + 0.007*\"nic\" + 0.004*\"mention\" + '\n",
      "  '0.004*\"case\" + 0.000*\"amazon\"'),\n",
      " (7,\n",
      "  '0.000*\"hangy\" + 0.000*\"timeing\" + 0.000*\"phonepe\" + 0.000*\"refresh\" + '\n",
      "  '0.000*\"misc\" + 0.000*\"utilise\" + 0.000*\"outgoing\" + 0.000*\"mobine\" + '\n",
      "  '0.000*\"figer\" + 0.000*\"phonescreen\"'),\n",
      " (8,\n",
      "  '0.476*\"good\" + 0.231*\"phone\" + 0.155*\"product\" + 0.092*\"price\" + '\n",
      "  '0.034*\"low\" + 0.000*\"amazon\" + 0.000*\"amazing\" + 0.000*\"superb\" + '\n",
      "  '0.000*\"day\" + 0.000*\"display\"'),\n",
      " (9,\n",
      "  '0.333*\"work\" + 0.172*\"delivery\" + 0.151*\"happy\" + 0.074*\"fine\" + '\n",
      "  '0.059*\"smart\" + 0.030*\"dad\" + 0.016*\"satisfactory\" + 0.000*\"amazon\" + '\n",
      "  '0.000*\"issue\" + 0.000*\"love\"'),\n",
      " (10,\n",
      "  '0.213*\"time\" + 0.111*\"cheap\" + 0.093*\"experience\" + 0.073*\"gb\" + '\n",
      "  '0.065*\"ram\" + 0.043*\"less\" + 0.042*\"size\" + 0.031*\"hand\" + 0.029*\"smooth\" + '\n",
      "  '0.029*\"game\"'),\n",
      " (11,\n",
      "  '0.231*\"hang\" + 0.088*\"call\" + 0.083*\"load\" + 0.076*\"sound\" + '\n",
      "  '0.062*\"affordable\" + 0.047*\"usage\" + 0.035*\"new\" + 0.034*\"speaker\" + '\n",
      "  '0.033*\"brand\" + 0.030*\"never\"'),\n",
      " (12,\n",
      "  '0.303*\"use\" + 0.158*\"get\" + 0.138*\"problem\" + 0.107*\"feature\" + '\n",
      "  '0.077*\"month\" + 0.064*\"even\" + 0.038*\"review\" + 0.004*\"avarage\" + '\n",
      "  '0.000*\"day\" + 0.000*\"amazon\"'),\n",
      " (13,\n",
      "  '0.351*\"battery\" + 0.163*\"life\" + 0.115*\"redmi\" + 0.095*\"great\" + '\n",
      "  '0.055*\"purchase\" + 0.038*\"charge\" + 0.032*\"take\" + 0.027*\"long\" + '\n",
      "  '0.018*\"properly\" + 0.014*\"hour\"'),\n",
      " (14,\n",
      "  '0.561*\"well\" + 0.091*\"model\" + 0.085*\"basic\" + 0.000*\"amazon\" + '\n",
      "  '0.000*\"display\" + 0.000*\"many\" + 0.000*\"service\" + 0.000*\"waste\" + '\n",
      "  '0.000*\"year\" + 0.000*\"amazing\"'),\n",
      " (15,\n",
      "  '0.430*\"budget\" + 0.173*\"super\" + 0.163*\"performance\" + 0.050*\"processor\" + '\n",
      "  '0.043*\"deliver\" + 0.032*\"option\" + 0.010*\"market\" + 0.000*\"amazon\" + '\n",
      "  '0.000*\"superb\" + 0.000*\"amazing\"'),\n",
      " (16,\n",
      "  '0.224*\"go\" + 0.194*\"also\" + 0.130*\"fast\" + 0.103*\"expect\" + 0.052*\"provide\" '\n",
      "  '+ 0.043*\"choice\" + 0.038*\"make\" + 0.012*\"expectation\" + 0.009*\"pay\" + '\n",
      "  '0.008*\"upto\"'),\n",
      " (17,\n",
      "  '0.296*\"average\" + 0.255*\"screen\" + 0.221*\"overall\" + 0.010*\"dull\" + '\n",
      "  '0.000*\"big\" + 0.000*\"sensor\" + 0.000*\"touch\" + 0.000*\"automatically\" + '\n",
      "  '0.000*\"amazon\" + 0.000*\"open\"'),\n",
      " (18,\n",
      "  '0.495*\"range\" + 0.142*\"really\" + 0.072*\"like\" + 0.054*\"miss\" + 0.026*\"mom\" '\n",
      "  '+ 0.013*\"gifted\" + 0.004*\"part\" + 0.000*\"amazon\" + 0.000*\"amazing\" + '\n",
      "  '0.000*\"love\"'),\n",
      " (19,\n",
      "  '0.926*\"nice\" + 0.000*\"amazon\" + 0.000*\"service\" + 0.000*\"display\" + '\n",
      "  '0.000*\"amazing\" + 0.000*\"superb\" + 0.000*\"love\" + 0.000*\"day\" + '\n",
      "  '0.000*\"satisfied\" + 0.000*\"issue\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the keyword of topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6b8e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -12.195543566449219\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  \n",
    "# a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23835978",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
